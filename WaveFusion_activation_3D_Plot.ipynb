{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 3D plots of activation\n",
    "Requires a -trans.fif file created during mne coreg. Requires the use of MRI and Freesurfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "z3JfsSspoUuU",
    "outputId": "1f0f4a7e-fa55-49ad-b3fc-dbf0d2ac07d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.2.0\n",
      "Torchvision Version:  0.4.0a0+6b959ee\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "import ntpath\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "from scipy import signal\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import mne\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, sys\n",
    "#from mayavi import mlab\n",
    "#mlab.init_notebook()\n",
    "%gui qt\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eusq_mjXgn6y"
   },
   "source": [
    "# 1.) Compute preds for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Edq9YIMyoUuX"
   },
   "outputs": [],
   "source": [
    "#beta value for multiplicative loss\n",
    "beta = 0.92\n",
    "\n",
    "#delta value for boosted fusion loss\n",
    "delta = 10.0\n",
    "\n",
    "#path to trained model weights of type torch.nn.Module.load_state_dict for \"model\"\n",
    "path_wts = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0KzX_YzoUuZ"
   },
   "source": [
    "## Dataset and DataLoader 1sec window\n",
    "configured for 26 patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3PGrfmhoUua"
   },
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    \"\"\"\n",
    "    Helper class to suppress mne print statements\n",
    "    \"\"\"\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JS4ykt30oUud"
   },
   "outputs": [],
   "source": [
    "#I changed the dataloader to an updated version.\n",
    "class Wavelet_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.samples = self.make_dataset(root_dir, \".fif\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def make_dataset(self, dir , extensions):\n",
    "        \"\"\"creates a list of paths to data in root data directory\n",
    "\n",
    "        Args:\n",
    "            dir: path to data directory of train/val datafiles i.e. ~/SMNI_TRAINTEST_DATA/train\n",
    "            class_to_index\n",
    "\n",
    "        Returns:\n",
    "            list: images list of pats to data\n",
    "        \"\"\"\n",
    "\n",
    "        images = []\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(dir)):\n",
    "            for fname in sorted(fnames):\n",
    "                if self.has_file_allowed_extension(fname, \".fif\"):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    cls = -1\n",
    "                    if fname.split('_')[2] == \"mild\":\n",
    "                        cls = 0\n",
    "                    elif fname.split('_')[2] == \"moderate\":\n",
    "                        cls = 1\n",
    "                    elif fname.split('_')[2] == \"severe\":\n",
    "                        cls = 2\n",
    "\n",
    "                    item = (path,cls)\n",
    "                    #print(item)\n",
    "                    images.append(item)\n",
    "\n",
    "        return images\n",
    "\n",
    "    def Wavelet(self,path:str):\n",
    "        \"\"\"\n",
    "        create data cubes using data from .csv file at path. of the form <\n",
    "        (Lead)x(frequencies)x(time) Power wavelete data types.\n",
    "\n",
    "        Args:\n",
    "            path to .csv file (should be passed by TesseractData and dataset)\n",
    "            ex: ~/SMNI_TRAINTEST_DATA/train/alcoholic/a_S3_377_069.csv\n",
    "\n",
    "        Returns: tess 3D numpy array containing time frequency transform data\n",
    "                 of shape (Lead)x(frequency)x(time).\n",
    "        \"\"\"\n",
    "        channels = 61\n",
    "        scale = 32 #scale param for morle wavelet\n",
    "        length = 250\n",
    "\n",
    "        with HiddenPrints():\n",
    "            raw = mne.io.read_raw_fif(path)\n",
    "        raw = raw.get_data(picks=raw.ch_names, start=0)\n",
    "\n",
    "        data = pd.DataFrame(data=raw)\n",
    "\n",
    "        y_voltage = np.empty([channels, length])\n",
    "        for i in range(channels):\n",
    "            y_voltage[i] = data.iloc[i]\n",
    "\n",
    "\n",
    "        # Generate a 3d array of channelXfreqXtime\n",
    "        waves_mag = np.empty([61, scale, 250 ], dtype=float) \n",
    "        # store the abs(coef) into waves_mag instead of computing waves_cmp\n",
    "        # then taking the absolute value of waves_cmp. I hope this speeds things up\n",
    "\n",
    "        # compute and store complex morlet transform for each lead\n",
    "        # THIS VERSION PUTS Lead First\n",
    "        for i in range(channels):\n",
    "            coef, freqs=pywt.cwt(y_voltage[i],np.arange(1,scale+1),'cmor0.4-1.0',sampling_period=1)\n",
    "            waves_mag[i,:,:] = copy.deepcopy(abs(coef))\n",
    "\n",
    "        return waves_mag\n",
    "        \n",
    "    def has_file_allowed_extension(self, filename, extensions):\n",
    "        \"\"\"Generic file extension checker. does\n",
    "\n",
    "        Args:\n",
    "            filename (string): path to a file\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the filename ends with a known image extension\n",
    "        \"\"\"\n",
    "        filename_lower = filename.lower()\n",
    "        return any(filename_lower.endswith(ext) for ext in extensions)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (tesseractTransform(sample(index), target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.Wavelet(path)\n",
    "        sample = np.array(sample).astype(np.float64)\n",
    "        sample = torch.FloatTensor(sample)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3s-EcDynoUul"
   },
   "outputs": [],
   "source": [
    "mean = [5.7504194894601505e-06,\n",
    "5.728741585181514e-06,\n",
    "7.237039053965088e-06,\n",
    "4.208074243624845e-06,\n",
    "2.50056270944241e-06,\n",
    "4.187197870766758e-06,\n",
    "7.32017148665085e-06,\n",
    "6.439270389808919e-06,\n",
    "2.1467175120274207e-06,\n",
    "2.3475471417550127e-06,\n",
    "6.92765799823113e-06,\n",
    "9.373363941055193e-06,\n",
    "6.720977282804776e-06,\n",
    "3.654530031713957e-06,\n",
    "7.354775270897619e-06,\n",
    "1.005174847817515e-05,\n",
    "1.0398115199924857e-05,\n",
    "8.134736021888628e-06,\n",
    "8.589935443835935e-06,\n",
    "1.1703290203058822e-05,\n",
    "4.1053606566116706e-06,\n",
    "1.4658332241735504e-05,\n",
    "1.2955417495042837e-05,\n",
    "1.2311520129481097e-05,\n",
    "1.3715734581283254e-05,\n",
    "1.718611863764373e-05,\n",
    "1.6169887774143943e-05,\n",
    "1.8119934887564533e-05,\n",
    "1.673298069550639e-05,\n",
    "1.819891762772844e-05,\n",
    "1.6308829853755876e-05,\n",
    "6.48752313737657e-06,\n",
    "4.570791071775696e-06,\n",
    "4.532000651713432e-06,\n",
    "6.532488790511118e-06,\n",
    "5.464546367466236e-06,\n",
    "2.919301209624429e-06,\n",
    "3.0568041456318864e-06,\n",
    "5.3192569407745355e-06,\n",
    "8.227752725951735e-06,\n",
    "4.358965567117618e-06,\n",
    "4.794040174267047e-06,\n",
    "8.304855411561447e-06,\n",
    "8.112487818368185e-06,\n",
    "4.633563600870139e-06,\n",
    "5.087105051877014e-06,\n",
    "8.74617345446718e-06,\n",
    "1.1613653614248209e-05,\n",
    "9.39294167273587e-06,\n",
    "7.921913058602362e-06,\n",
    "1.0266379722641722e-05,\n",
    "1.3078571988562245e-05,\n",
    "1.3931141269894663e-05,\n",
    "1.1994570612201592e-05,\n",
    "1.2464052821413853e-05,\n",
    "1.5985735642926502e-05,\n",
    "1.8228924335767787e-05,\n",
    "1.678402784160463e-05,\n",
    "1.608585899584544e-05,\n",
    "1.713535016683776e-05,\n",
    "2.011528695302471e-05]\n",
    "\n",
    "dev = [6.057284722117714e-06,\n",
    "5.955594623062248e-06,\n",
    "7.51299863285755e-06,\n",
    "4.28137984287368e-06,\n",
    "2.7263079414823437e-06,\n",
    "4.270560061930021e-06,\n",
    "7.623474677409314e-06,\n",
    "6.871208281970108e-06,\n",
    "2.1786990922699215e-06,\n",
    "2.404251273737509e-06,\n",
    "7.372362604591492e-06,\n",
    "1.0225397268429354e-05,\n",
    "7.810197348585481e-06,\n",
    "4.3948422182336315e-06,\n",
    "8.45789340116696e-06,\n",
    "1.1624432890069268e-05,\n",
    "1.2439505171691405e-05,\n",
    "1.0217743960394727e-05,\n",
    "1.0762761009416062e-05,\n",
    "1.4475259894639832e-05,\n",
    "4.416342590595693e-06,\n",
    "1.873906338603034e-05,\n",
    "1.654761534279868e-05,\n",
    "1.5858310351588178e-05,\n",
    "1.7443518418910416e-05,\n",
    "2.246008604131442e-05,\n",
    "2.1030259718298304e-05,\n",
    "2.4856477995226744e-05,\n",
    "2.1501386127451786e-05,\n",
    "2.4235498658256147e-05,\n",
    "2.109854948315952e-05,\n",
    "6.702665391715863e-06,\n",
    "4.824524504629907e-06,\n",
    "4.7471229608639915e-06,\n",
    "6.699013264300426e-06,\n",
    "5.880738444313614e-06,\n",
    "3.0474061729009764e-06,\n",
    "3.285427320028878e-06,\n",
    "5.3602471609911775e-06,\n",
    "8.954077171320513e-06,\n",
    "4.57610275169536e-06,\n",
    "4.947610111168858e-06,\n",
    "8.976876550005724e-06,\n",
    "9.08240022985891e-06,\n",
    "6.068825347797623e-06,\n",
    "6.078034066110466e-06,\n",
    "1.0175379250455029e-05,\n",
    "1.3681107179448334e-05,\n",
    "1.1456005937018132e-05,\n",
    "1.0202288960524899e-05,\n",
    "1.27642286872347e-05,\n",
    "1.6238574252936906e-05,\n",
    "1.7985560336626746e-05,\n",
    "1.538079346285363e-05,\n",
    "1.5763985162523097e-05,\n",
    "2.0444270837946755e-05,\n",
    "2.532880438342928e-05,\n",
    "2.229767554392438e-05,\n",
    "2.0638056594009807e-05,\n",
    "2.1945532436029406e-05,\n",
    "2.7350538859202916e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azPA8k66oUut"
   },
   "outputs": [],
   "source": [
    "def boosted_fusion_loss(preds, labels, beta, delta):\n",
    "    \"\"\"impements boosted loss by Implements multiplicative fusion loss by Liu\n",
    "    et al https://arxiv.org/pdf/1805.11730.pdf\n",
    "    args:\n",
    "        preds: predictions returned by wavelet_fusion model: a list of size ||batchsize||\n",
    "        labels: labels for datapoint list of size ||batchsize||\n",
    "        b: scaling factor 0<= b 0<=1\n",
    "        delta: difference factor 0 <= delta\n",
    "    Return:\n",
    "        1-d tensor that can be back propagated.\n",
    "    \"\"\"\n",
    "    channels = 61\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        tmp_loss0 = torch.FloatTensor([0]).to(device)\n",
    "        tmp_loss1 = torch.FloatTensor([0]).to(device)\n",
    "        tmp_loss2 = torch.FloatTensor([0]).to(device)\n",
    "        coeffs_arr = []\n",
    "        if labels[i] == 0: #class loss for t=0\n",
    "            \n",
    "            #compute loss for p^0\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][0])\n",
    "                \n",
    "                if preds[i][j][0] != 1 and preds[i][j][0] != 0: \n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    for k in range(channels):\n",
    "                        #compute weighting coefficient\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][0])\n",
    "                            #coeffs.append(coeff.item())\n",
    "\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss0 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][0])\n",
    "            \n",
    "            \n",
    "            \n",
    "            #compute loss for p^1\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][1])\n",
    "                \n",
    "                if preds[i][j][1] != 1 and preds[i][j][1] != 0:\n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    #compute weighting coefficent\n",
    "                    for k in range(channels):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][1])\n",
    "                            #coeffs.append(coeff.item())\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss1 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][1])\n",
    "            \n",
    "\n",
    "            #compute loss for p^2\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][1])\n",
    "                \n",
    "                if preds[i][j][2] != 1 and preds[i][j][2] != 0:\n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    #compute weighting coefficent\n",
    "                    for k in range(channels):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][2])\n",
    "                            #coeffs.append(coeff.item())\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss2 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][2])\n",
    "            \n",
    "            \n",
    "            \n",
    "            #update loss\n",
    "            if tmp_loss0 + delta >= tmp_loss1 or tmp_loss0 + delta >= tmp_loss2:\n",
    "                #compute loss for p^0\n",
    "                loss += tmp_loss0\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        elif labels[i] == 1: #class loss for t=1\n",
    "\n",
    "            #compute loss for p^0\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][0])\n",
    "                \n",
    "                if preds[i][j][0] != 1 and preds[i][j][0] != 0: \n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    for k in range(channels):\n",
    "                        #compute weighting coefficient\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][0])\n",
    "                            #coeffs.append(coeff.item())\n",
    "\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss0 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][0])\n",
    "            \n",
    "            \n",
    "            \n",
    "            #compute loss for p^1\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][1])\n",
    "                \n",
    "                if preds[i][j][1] != 1 and preds[i][j][1] != 0:\n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    #compute weighting coefficent\n",
    "                    for k in range(channels):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][1])\n",
    "                            #coeffs.append(coeff.item())\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss1 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][1])\n",
    "                    \n",
    "            \n",
    "            #compute loss for p^2\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][1])\n",
    "                \n",
    "                if preds[i][j][2] != 1 and preds[i][j][2] != 0:\n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    #compute weighting coefficent\n",
    "                    for k in range(channels):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][2])\n",
    "                            #coeffs.append(coeff.item())\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss2 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][2])            \n",
    "\n",
    "\n",
    "            if tmp_loss1 + delta >= tmp_loss0 or tmp_loss1 + delta >= tmp_loss2:\n",
    "                loss += tmp_loss1\n",
    "                \n",
    "        elif labels[i] == 2:\n",
    "            \n",
    "\n",
    "            #compute loss for p^0\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][0])\n",
    "                \n",
    "                if preds[i][j][0] != 1 and preds[i][j][0] != 0: \n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    for k in range(channels):\n",
    "                        #compute weighting coefficient\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][0])\n",
    "                            #coeffs.append(coeff.item())\n",
    "\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss0 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][0])\n",
    "            \n",
    "            \n",
    "            \n",
    "            #compute loss for p^1\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][1])\n",
    "                \n",
    "                if preds[i][j][1] != 1 and preds[i][j][1] != 0:\n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    #compute weighting coefficent\n",
    "                    for k in range(channels):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][1])\n",
    "                            #coeffs.append(coeff.item())\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss1 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][1])\n",
    "                    \n",
    "            \n",
    "            #compute loss for p^2\n",
    "            for j in range(channels):\n",
    "                #print(preds[i][j][1])\n",
    "                \n",
    "                if preds[i][j][2] != 1 and preds[i][j][2] != 0:\n",
    "                    coeff = 1\n",
    "                    #coeffs = []\n",
    "                    #compute weighting coefficent\n",
    "                    for k in range(channels):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][2])\n",
    "                            #coeffs.append(coeff.item())\n",
    "                    #print(len(coeffs))\n",
    "                    #print(coeffs)\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    tmp_loss2 += (-1.0)*torch.pow( coeff, beta/(channels-1) )*torch.log(preds[i][j][2])            \n",
    "\n",
    "\n",
    "            if tmp_loss2 + delta >= tmp_loss0 or tmp_loss1 + delta >= tmp_loss1:\n",
    "                loss += tmp_loss2            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KM88bik4oUuw"
   },
   "outputs": [],
   "source": [
    "class Wave_Lead_Conv(nn.Module):\n",
    "    \"\"\"\n",
    "    Wave_Lead_Conv is a convolution model designed to convolve over a single scaleogram,\n",
    "    of shape (1,freq,time) generated by one EEG lead. this model is the portion of \n",
    "    onv2d_by_Leads model without the last linear layer that combines the output for each\n",
    "    lead.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Wave_Lead_Conv,self).__init__()\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(1,8, kernel_size=(3,4), stride=(1,2), padding=(1,2)) \n",
    "        self.maxPool1 = nn.MaxPool2d((2,2))\n",
    "      \n",
    "        self.conv2 = nn.Conv2d(8,16, kernel_size=(4,3), stride=(2,2), padding=1)\n",
    "        self.maxPool2 = nn.MaxPool2d((2,2))\n",
    "        \n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,32, kernel_size=(3,4), stride=(1,2), padding=1)\n",
    "        self.maxPool3 = nn.MaxPool2d((2,2))\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(32,64, kernel_size=(2,4), stride=(1,1))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.50)\n",
    "        self.fc1 = nn.Linear(64,3) \n",
    "   \n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #convolve over channels only\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxPool1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.maxPool2(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.maxPool3(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = x.view(64)\n",
    "        x = self.fc1(x) \n",
    "        x = self.softmax(x)\n",
    "        #print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HuiUOuLoUuy"
   },
   "outputs": [],
   "source": [
    "class Wave_Fusion_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Wave Fusion Model. Contains 64 Wave Lead Convs that convolves over each \n",
    "    eeg Lead. Implements multiplicative fusion loss by Liu\n",
    "    et al https://arxiv.org/pdf/1805.11730.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, beta):\n",
    "        self.leads = 61\n",
    "        self.beta = beta\n",
    "        super(Wave_Fusion_Model,self).__init__()\n",
    "        for i in range(self.leads):\n",
    "            self.add_module('Wave_Lead_Conv' + str(i), Wave_Lead_Conv())\n",
    "        self.Wave_Lead_Conv = AttrProxy(self, 'Wave_Lead_Conv')\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        feeds each eeg channel in x to a Wave_Lead_Conv\n",
    "        x: a tensor of shape BatchSize x self.leads x 32 x 256\n",
    "        returns: \n",
    "        On training: a list of size (batchsize, num_lead) w/ each entry a [1,2] tensor of softmax probabilities for each class\n",
    "        On eval: a tensor containing the class losses for each data in the batch\n",
    "        \"\"\"\n",
    "        tmp = []\n",
    "        preds = []\n",
    "        bs = len(x[:,0,0,0])\n",
    "\n",
    "        #feed data to the Wave_Lead_Convs and return list of predictions\n",
    "        for i in range(bs):\n",
    "            tmp = []\n",
    "            for j in range(self.leads):\n",
    "                #each lead to a wave_lead_conv. reshape to 1,1,32,250\n",
    "                \n",
    "                t1 = self.Wave_Lead_Conv.__getitem__(j)(x[i,j,:,:].view(1,1,32,250))\n",
    "                t1 = t1.clone()\n",
    "                #t1.retain_grad()\n",
    "                tmp.append(t1)\n",
    "            \n",
    "            preds.append(tmp)\n",
    "        #training prediction is a list of size (batchsize, num_lead) w/ each entry a [1,2] tensor of softmax probabilities for each class\n",
    "        if self.training:\n",
    "            return preds\n",
    "        #eval predictions are the loss for each class. \n",
    "        else:\n",
    "\n",
    "            #Liu Method\n",
    "            pred_tmp = []\n",
    "            for i in range(bs):\n",
    "                loss0 = 0\n",
    "                loss1 = 0\n",
    "                loss2 = 0\n",
    "                coeff0 = []\n",
    "                coeff1 = []\n",
    "                coeff2 = []\n",
    "\n",
    "\n",
    "                #compute the class loss0\n",
    "                for j in range(self.leads):\n",
    "                    #compute weighting coefficient\n",
    "                    coeff = 1\n",
    "                    for k in range(self.leads):\n",
    "\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][0])\n",
    "\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "                    coeff0.append(coeff)\n",
    "                    #calculate loss, add\n",
    "                    loss0 += (-1.0)*torch.pow( coeff, beta/(self.leads-1) )*torch.log(preds[i][j][0])\n",
    "                    \n",
    "                    #loss0 += (-1.0)*torch.log(preds[i][j][0])\n",
    "                \n",
    "                #calculate class loss 1\n",
    "                for j in range(self.leads):\n",
    "                    \n",
    "                    #if preds[i][j][1] != 1 and preds[i][j][1] != 0:\n",
    "                    #compute weighting coefficient\n",
    "                    coeff = 1\n",
    "                    for k in range(self.leads):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][1])\n",
    "\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "                    coeff1.append(coeff)\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    loss1 += (-1.0)*torch.pow( coeff, beta/(self.leads-1) )*torch.log(preds[i][j][1])\n",
    "                    \n",
    "                    #loss1 += (-1.0)*torch.log(preds[i][j][1])\n",
    "                    \n",
    "                #calculate class loss 2\n",
    "                for j in range(self.leads):\n",
    "                    \n",
    "                    #if preds[i][j][1] != 1 and preds[i][j][1] != 0:\n",
    "                    #compute weighting coefficient\n",
    "                    coeff = 1\n",
    "                    for k in range(self.leads):\n",
    "                        if k != j:\n",
    "                            coeff = coeff * (1-preds[i][k][2])\n",
    "\n",
    "                    #detach coefficient from computation graph\n",
    "                    coeff=coeff.detach()\n",
    "                    coeff2.append(coeff)\n",
    "\n",
    "                    #calculate loss, add\n",
    "                    loss2 += (-1.0)*torch.pow( coeff, beta/(self.leads-1) )*torch.log(preds[i][j][2])\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #combine losses into 1x3 tensor\n",
    "                tmp = torch.stack((loss0,loss1,loss2), 0)\n",
    "\n",
    "                #combine coefficients for each prediction into 1x61 tensors\n",
    "\n",
    "                coeff0 = torch.FloatTensor(coeff0)\n",
    "                coeff1 = torch.FloatTensor(coeff1)\n",
    "                coeff2 = torch.FloatTensor(coeff2)\n",
    "\n",
    "                coeffs = torch.stack((coeff0,coeff1,coeff2))\n",
    "                pred_tmp.append(tmp)\n",
    "            \n",
    "            #stack all losses together as tensor\n",
    "            preds = torch.stack(pred_tmp)\n",
    "            \n",
    "            return preds, coeffs\n",
    "\n",
    "\n",
    "class AttrProxy(object):\n",
    "    \"\"\"indexes Wave_Lead_Conv models as Wave_Lead_Conv0, Wave_Lead_Conv1,...\n",
    "    Wave_Lead_Conv63  in the Wave_Fusion_Model.\"\"\"\n",
    "    def __init__(self, module, prefix):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            module: the Wave_Lead_Conv component to be named\n",
    "            prefix: int\n",
    "        \"\"\"\n",
    "        self.module = module\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"retrieves the ith Wave_Lead_Conv from Wave_Fusion_Model.\"\"\"\n",
    "        return getattr(self.module, self.prefix + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 40
    },
    "colab_type": "code",
    "id": "N6Cgx9QuoUu6",
    "outputId": "078afb15-cd9f-4155-e780-da2e3e73ff66"
   },
   "outputs": [],
   "source": [
    "#set to train w/ GPU if available else cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = Wave_Fusion_Model(beta = beta).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 40
    },
    "colab_type": "code",
    "id": "IOpVi_4-oUu8",
    "outputId": "114598f5-9fa9-40d8-b854-3fde110feca9"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load( path_wts,map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "best_acc = checkpoint['acc']\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zllsupLezsFB"
   },
   "source": [
    "Create Coefficient Interpolation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DM0ntLTbqsd8"
   },
   "outputs": [],
   "source": [
    "chan_names = ['Fp1',\n",
    " 'Fp2',\n",
    " 'F7',\n",
    " 'F3',\n",
    " 'Fz',\n",
    " 'F4',\n",
    " 'F8',\n",
    " 'FC5',\n",
    " 'FC1',\n",
    " 'FC2',\n",
    " 'FC6',\n",
    " 'T7',\n",
    " 'C3',\n",
    " 'Cz',\n",
    " 'C4',\n",
    " 'T8',\n",
    " 'CP5',\n",
    " 'CP1',\n",
    " 'CP2',\n",
    " 'CP6',\n",
    " 'AFz',\n",
    " 'P7',\n",
    " 'P3',\n",
    " 'Pz',\n",
    " 'P4',\n",
    " 'P8',\n",
    " 'PO9',\n",
    " 'O1',\n",
    " 'Oz',\n",
    " 'O2',\n",
    " 'PO10',\n",
    " 'AF7',\n",
    " 'AF3',\n",
    " 'AF4',\n",
    " 'AF8',\n",
    " 'F5',\n",
    " 'F1',\n",
    " 'F2',\n",
    " 'F6',\n",
    " 'FT7',\n",
    " 'FC3',\n",
    " 'FC4',\n",
    " 'FT8',\n",
    " 'C5',\n",
    " 'C1',\n",
    " 'C2',\n",
    " 'C6',\n",
    " 'TP7',\n",
    " 'CP3',\n",
    " 'CPz',\n",
    " 'CP4',\n",
    " 'TP8',\n",
    " 'P5',\n",
    " 'P1',\n",
    " 'P2',\n",
    " 'P6',\n",
    " 'PO7',\n",
    " 'PO3',\n",
    " 'POz',\n",
    " 'PO4',\n",
    " 'PO8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLmJmJh30nBE"
   },
   "outputs": [],
   "source": [
    "def Wavelet(path:str):\n",
    "    \"\"\"\n",
    "    create data cubes using data from .csv file at path. of the form <\n",
    "    (Lead)x(frequencies)x(time) Power wavelete data types.\n",
    "\n",
    "    Args:\n",
    "        path to .csv file (should be passed by TesseractData and dataset)\n",
    "        ex: ~/SMNI_TRAINTEST_DATA/train/alcoholic/a_S3_377_069.csv\n",
    "\n",
    "    Returns: tess 3D numpy array containing time frequency transform data\n",
    "                of shape (Lead)x(frequency)x(time).\n",
    "    \"\"\"\n",
    "    channels = 61\n",
    "    scale = 32 #scale param for morle wavelet\n",
    "    length = 250\n",
    "\n",
    "    with HiddenPrints():\n",
    "        raw = mne.io.read_raw_fif(path)\n",
    "    raw = raw.get_data(picks=raw.ch_names, start=0)\n",
    "\n",
    "    data = pd.DataFrame(data=raw)\n",
    "\n",
    "    y_voltage = np.empty([channels, length])\n",
    "    for i in range(channels):\n",
    "        y_voltage[i] = data.iloc[i]\n",
    "\n",
    "\n",
    "    # Generate a 3d array of channelXfreqXtime\n",
    "    waves_mag = np.empty([61, scale, 250 ], dtype=float) \n",
    "    # store the abs(coef) into waves_mag instead of computing waves_cmp\n",
    "    # then taking the absolute value of waves_cmp. I hope this speeds things up\n",
    "\n",
    "    # compute and store complex morlet transform for each lead\n",
    "    # THIS VERSION PUTS Lead First\n",
    "    for i in range(channels):\n",
    "        coef, freqs=pywt.cwt(y_voltage[i],np.arange(1,scale+1),'cmor0.4-1.0',sampling_period=1)\n",
    "        waves_mag[i,:,:] = copy.deepcopy(abs(coef))\n",
    "\n",
    "\n",
    "    return waves_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSKXiPMA0nBL"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(path, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "    Args:\n",
    "        PIL_img (PIL_img): PIL Image or numpy array to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (torch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    ten = torch.FloatTensor(Wavelet(path))\n",
    "    ten = data_transforms['val'](ten)\n",
    "    return ten.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Normalize(mean=mean,std=dev)\n",
    "    ]),\n",
    "    'val': torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Normalize(mean=mean,std=dev)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1GAittpD0oJX",
    "outputId": "3899f787-d1e1-4c14-ec26-f28a697abd1d"
   },
   "outputs": [],
   "source": [
    "wmild = preprocess_image('input_images/sub-032320_EC_mild_1_raw.fif')\n",
    "wmoderate = preprocess_image('input_images/sub-032464_EC_moderate_75_raw.fif')\n",
    "wsevere =  preprocess_image('input_images/sub-032455_EC_severe_101_raw.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make 3D plots\n",
    "Requires MNE, .trans file made my freesurfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVeMBzef2MOZ"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, mild_coeffs = model(wmild)\n",
    "_, mod_coeffs = model(wmoderate)\n",
    "_, sev_coeffs = model(wsevere)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJQ2rlUqLlqL"
   },
   "outputs": [],
   "source": [
    "# Create mild activations\n",
    "#mildex_act = np.array(((mild_coeffs[0] - mild_coeffs[0].min() )/(mild_coeffs[0].max()-mild_coeffs[0].min())))\n",
    "#mildex_act =  np.expand_dims(mildex_act, axis=1)\n",
    "\n",
    "# Create moderate activations\n",
    "#modex_act = np.array(((mod_coeffs[0] - mod_coeffs[0].min() )/(mod_coeffs[0].max()-mod_coeffs[0].min())))\n",
    "#modex_act =  np.expand_dims(modex_act, axis=1)\n",
    "#print(modex_act)\n",
    "\n",
    "# Create severe activations\n",
    "sev_act = np.array(((sev_coeffs[0] - sev_coeffs[0].min() )/(sev_coeffs[0].max()-sev_coeffs[0].min())))\n",
    "sev_act =  np.expand_dims(sev_act, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G653XVRRLlqU"
   },
   "outputs": [],
   "source": [
    "# Definition of channel types and names.\n",
    "ch_types = ['EEG']\n",
    "ch_names = chan_names\n",
    "sfreq = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cag-RXg7Llqa"
   },
   "outputs": [],
   "source": [
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=['eeg']*61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "wV_U_smJLlqc",
    "outputId": "1cadfd3f-fa6c-4edb-d7fa-8bc9af1e6610"
   },
   "outputs": [],
   "source": [
    "# Create mne objects for interpolation\n",
    "#mild_raw = mne.io.RawArray(mildex_act , info) \n",
    "#mod_raw = mne.io.RawArray(modex_act , info) \n",
    "sev_raw = mne.io.RawArray(sev_act, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "d4OjZCanLlqj",
    "outputId": "fb3e51da-b90e-4054-f35f-60c922563256"
   },
   "outputs": [],
   "source": [
    "#set montages\n",
    "ten_twenty_montage = mne.channels.make_standard_montage('standard_1020')\n",
    "print(\"Setting montage...\")\n",
    "print(ten_twenty_montage)\n",
    "#mild_raw.set_montage(ten_twenty_montage)\n",
    "#mod_raw.set_montage(ten_twenty_montage)\n",
    "sev_raw.set_montage(ten_twenty_montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24NfpMCHLlql"
   },
   "outputs": [],
   "source": [
    "# Create envoked response arrays\n",
    "#mild_evoked = mne.EvokedArray(mildex_act, mild_raw.info)\n",
    "#mod_evoked = mne.EvokedArray(modex_act, mod_raw.info)\n",
    "sev_evoked = mne.EvokedArray(sev_act,sev_raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = \"/Applications/freesurfer/7.1.1/subjects/sub-032323/sub-032323-trans.fif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIm7r000pHfC"
   },
   "outputs": [],
   "source": [
    "trans = mne.read_trans(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = \"/Applications/freesurfer/7.1.1/subjects/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "QnSgWtOYbGkc",
    "outputId": "646ba72a-4c11-4a3e-a51e-583a1ba22db7"
   },
   "outputs": [],
   "source": [
    "#_map = mne.make_field_map(mod_evoked, subject='sub-032323',trans = tp, ch_type = 'eeg',meg_surf='helmet',subjects_dir=sd)\n",
    "_map = mne.make_field_map(sev_evoked, subject='sub-032323',trans = tp, ch_type = 'eeg',meg_surf='helmet',subjects_dir=sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sev_evoked.plot_field(_map)\n",
    "\n",
    "mne.viz.set_3d_title(fig, 'meg', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiH2qZTcrVYN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Wave_LEMON_activation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "095a0ef1ca2c4c9dbae6458647371248": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "15af93ba35974f8a90c75a48a6562ce9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15c022fcdc3042b89af9ac165d027347": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7899c4685c444d539aa118df38405f53",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fcd4d07c50014e8ab3306ddd69ce5fd4",
      "value": " 45/45 [07:45&lt;00:00, 10.51s/it]"
     }
    },
    "18d97bf28fab4a46b1751e36b266f88b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f94343dff74c1e95b74288dcd30ca2",
       "IPY_MODEL_8c76dc29438848f887c4b9e7ada85ee6"
      ],
      "layout": "IPY_MODEL_ebdd0e052d3d4b51bdb671251941f242"
     }
    },
    "2716b9bfe4a643e9b8b266b6ba22a788": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46c097189e514b49ae09ffd629c2ebea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb3b3ce124ba432488a80114a1c67408",
       "IPY_MODEL_15c022fcdc3042b89af9ac165d027347"
      ],
      "layout": "IPY_MODEL_9f543535488f4232b5751a560edf8f30"
     }
    },
    "7899c4685c444d539aa118df38405f53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78f94343dff74c1e95b74288dcd30ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9bf36cde14b4ee6a42cb03173686fed",
      "max": 1652769680,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4b4573ac1e943e39828753596d490df",
      "value": 1652769680
     }
    },
    "8c76dc29438848f887c4b9e7ada85ee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15af93ba35974f8a90c75a48a6562ce9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9fbf3e6118a941cfa2802f827a0e3674",
      "value": " Downloading : 1.54G/1.54G [01:29&lt;00:00,    18.5MB/s]"
     }
    },
    "9f543535488f4232b5751a560edf8f30": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fbf3e6118a941cfa2802f827a0e3674": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9bf36cde14b4ee6a42cb03173686fed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b4573ac1e943e39828753596d490df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cb3b3ce124ba432488a80114a1c67408": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "batch: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2716b9bfe4a643e9b8b266b6ba22a788",
      "max": 45,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_095a0ef1ca2c4c9dbae6458647371248",
      "value": 45
     }
    },
    "ebdd0e052d3d4b51bdb671251941f242": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcd4d07c50014e8ab3306ddd69ce5fd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
